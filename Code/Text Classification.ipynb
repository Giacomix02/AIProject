{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importiamo le librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-19T21:34:35.781921500Z",
     "start_time": "2024-02-19T21:34:34.645418900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\giaco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\giaco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\giaco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# numpy arrays\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# NLP\n",
    "import string\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from Code.NLTKVectorizer import NLTKVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression\n",
    "from sklearn.naive_bayes import MultinomialNB  # Naive Bayes\n",
    "from sklearn.svm import LinearSVC  # SVM\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "# Model explainability\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# other\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "from functools import partial\n",
    "import joblib\n",
    "\n",
    "#nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "en_stop_words = list(set(stopwords.words(\"english\")))\n",
    "\n",
    "# aggiungo a en_stop_words le parole dal file da noi creato\n",
    "with open('stopwordsPersonali', 'r') as file:\n",
    "    for line in file:\n",
    "        en_stop_words.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    " assegniamo i dataset di training e test alle variabili di train e test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup dati iniziali"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv('Dataset/archive/train.csv')\n",
    "dfTest = pd.read_csv('Dataset/archive/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T21:34:42.932963200Z",
     "start_time": "2024-02-19T21:34:35.781921500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train = dfTrain['question_content']\n",
    "y_train = dfTrain['topic']\n",
    "X_test = dfTest['question_content']\n",
    "y_test = dfTest['topic']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T21:34:42.978152400Z",
     "start_time": "2024-02-19T21:34:42.942479400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "## Generatore della color palette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "Questa funzione viene utilizata per creare una *palette* di `n` colori di `palette_name` colori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-19T14:41:47.991860100Z",
     "start_time": "2024-02-19T14:41:47.960777900Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_n_color_palette(palette_name, n_colors, as_hex=False):\n",
    "    palette = sns.color_palette(palette=palette_name, n_colors=n_colors)\n",
    "    if as_hex:\n",
    "        palette = palette.as_hex()\n",
    "    palette.reverse()\n",
    "    return palette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "## Plotly export chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "Questa funzione è utilizzata per esportare l' HTML di plotly `fig_obj`, e salvarlo in: `assets/file_name.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-19T14:41:48.071800300Z",
     "start_time": "2024-02-19T14:41:47.977737800Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_fig_as_div(fig_obj, file_name):\n",
    "    with open(f\"{file_name}\", \"w\") as fig_file:\n",
    "        fig_div_string = plotly.offline.plot(\n",
    "            figure_or_data=fig_obj, output_type=\"div\", include_plotlyjs=\"cdn\"\n",
    "        )\n",
    "        fig_file.write(fig_div_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "La funzione genera il report di classificazione per le previsioni del modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "## Funzione per il confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "Questa funzione genera una confusion map per le previsioni del modello"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_confusion_matrix(y_true, y_pred, labels):\n",
    "\n",
    "    # calcola la confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)\n",
    "    \n",
    "    \n",
    "    sum = 0\n",
    "    diag = 0\n",
    "    \n",
    "    for i in range(len(conf_matrix)):\n",
    "        for j in range(len(conf_matrix[i])):\n",
    "            sum += conf_matrix[i][j]\n",
    "            if i == j:\n",
    "                diag += conf_matrix[i][j]\n",
    "            \n",
    "    \n",
    "    \n",
    "    print(f\"Diagonale: {diag}, Totale: {sum}\")\n",
    "    print(f\"Accuracy: {(diag/sum)*100}%\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    conf_matrix = np.flipud(conf_matrix)\n",
    "\n",
    "    # crea una heatmap annotata della matrice di confusione\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        conf_matrix, x=labels.tolist(), y=labels.tolist()[::-1]\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=800,\n",
    "        title_text=\"<i><b>Confusion matrix</b></i>\",\n",
    "        xaxis_title=\"Predicted category\",\n",
    "        yaxis_title=\"Real category\",\n",
    "        plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "        paper_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "        font={\n",
    "            \"family\": \"Courier New, monospace\",\n",
    "            \"size\": 14,\n",
    "            # 'color': \"#eaeaea\"\n",
    "        },\n",
    "    )\n",
    "    fig.update_xaxes(tickangle=-45)\n",
    "    fig[\"data\"][0][\"showscale\"] = True\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-19T21:34:48.429085100Z",
     "start_time": "2024-02-19T21:34:48.403746300Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzione per il classification report"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_classification_report(y_true, y_pred, target_names):\n",
    "\n",
    "    # calcola il report di classificazione e lo converte in un DataFrame\n",
    "    \n",
    "    clf_report = classification_report(\n",
    "        y_true=y_true, y_pred=y_pred, target_names=target_names, output_dict=True\n",
    "    )\n",
    "    clf_report_df = pd.DataFrame(data=clf_report)\n",
    "    clf_report_df = clf_report_df.T\n",
    "    clf_report_df.drop(columns=[\"support\"], inplace=True)\n",
    "\n",
    "    measures = clf_report_df.columns.tolist()\n",
    "    classes = clf_report_df.index.tolist()\n",
    "\n",
    "    # crea un heatmap annotato di plotly e aggiorna lo stile\n",
    "    \n",
    "    fig = ff.create_annotated_heatmap(clf_report_df.values, x=measures, y=classes)\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=800,\n",
    "        title_text=\"<i><b>Classification report</b></i>\",\n",
    "        xaxis_title=\"Measures\",\n",
    "        yaxis_title=\"Class\",\n",
    "        plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "        paper_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "        font={\n",
    "            \"family\": \"Courier New, monospace\",\n",
    "            \"size\": 14,\n",
    "            # 'color': \"#eaeaea\"\n",
    "        },\n",
    "    )\n",
    "    fig.update_xaxes(tickangle=-45)\n",
    "    fig[\"data\"][0][\"showscale\"] = True\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-19T14:41:48.117519Z",
     "start_time": "2024-02-19T14:41:47.995366200Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calcola per ogni topic nel dataset il numero di domande per topic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-19T14:42:10.120673900Z",
     "start_time": "2024-02-19T14:42:09.365519700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfTrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m categories_statistics_df \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mdfTrain\u001B[49m\u001B[38;5;241m.\u001B[39mgroupby(by\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtopic\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;241m.\u001B[39magg(\n\u001B[0;32m      4\u001B[0m         [\n\u001B[0;32m      5\u001B[0m             (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcount\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39msize),\n\u001B[0;32m      6\u001B[0m         ]\n\u001B[0;32m      7\u001B[0m     )\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcount\u001B[39m\u001B[38;5;124m\"\u001B[39m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     10\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dfTrain' is not defined"
     ]
    }
   ],
   "source": [
    "categories_statistics_df = (\n",
    "    dfTrain.groupby(by=\"topic\")[\"id\"]\n",
    "    .agg(\n",
    "        [\n",
    "            (\"count\", lambda x: x.size),\n",
    "        ]\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calcola per ogni topic nel dataset la lunghezza media delle domande per topic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "categories_statistics_df_questions = (\n",
    "    dfTrain.groupby(by=\"topic\")[\"question_content\"]\n",
    "    .agg(\n",
    "        [\n",
    "            (\"mean\", lambda x: x.str.len().mean()),\n",
    "            (\"max\", lambda x: x.str.len().max()),\n",
    "            (\"min\", lambda x: x.str.len().min()),\n",
    "        ]\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T22:45:06.028764100Z",
     "start_time": "2024-02-18T22:45:03.489231Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grafico domande per topic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "Usa un grafico a torta per mostrare le percentuali di domande per ogni topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "blue_palette = get_n_color_palette(\"Blues\", 20, True)\n",
    "\n",
    "fig = px.pie(\n",
    "    data_frame=categories_statistics_df,\n",
    "    names=\"topic\",\n",
    "    values=\"count\",\n",
    "    color_discrete_sequence=blue_palette,\n",
    "    title=\"Percentuale di domande per topic\",\n",
    "    width=800,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    {\n",
    "        \"plot_bgcolor\": \"rgba(0, 0, 0, 0)\",\n",
    "        \"paper_bgcolor\": \"rgba(0, 0, 0, 0)\",\n",
    "        \"font\": {\n",
    "            \"family\": \"Courier New, monospace\",\n",
    "            \"size\": 14,\n",
    "            # 'color': \"#eaeaea\"\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "\n",
    "Possiamo vedere che il dataset è *bilanciato*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-10T23:07:33.118633300Z",
     "start_time": "2024-02-10T23:07:33.036296400Z"
    }
   },
   "outputs": [],
   "source": [
    "# salvo il grafico in un file html\n",
    "save_fig_as_div(fig, file_name='charts/categories-percentages-pie-chart.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "## Grafico lunghezza media delle domande per topic:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "Usa un diagramma a barre per mostrare la lunghezza media delle domande per ogni topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "chart_labels = {\"mean\": \"Lunghezza delle domande\", \"Topic\": \"Topic type\"}\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame=categories_statistics_df_questions.sort_values(by=\"mean\"),\n",
    "    x=\"topic\",\n",
    "    y=\"mean\",\n",
    "    color=\"mean\",\n",
    "    labels=chart_labels,\n",
    "    title=\"Lunghezza media delle domande per topic\",\n",
    "    width=800,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    {\n",
    "        \"plot_bgcolor\": \"rgba(0, 0, 0, 0)\",\n",
    "        \"paper_bgcolor\": \"rgba(0, 0, 0, 0)\",\n",
    "        \"font\": {\n",
    "            \"family\": \"Courier New, monospace\",\n",
    "            \"size\": 14,\n",
    "            # 'color': \"#eaeaea\"\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "# rotate x-axis ticks\n",
    "fig.update_xaxes(tickangle=-45)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "Notiamo che la lunghezza delle domande è ben distrubuita per tutti i topic, tranne per il topic 0 (Society & Culture), 8 (Family & Relationships) e 9 (Politics & Government), che hanno una lunghezza media delle domande leggermente più lunga rispetto agli altri topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-10T23:11:00.245297900Z",
     "start_time": "2024-02-10T23:11:00.147294700Z"
    }
   },
   "outputs": [],
   "source": [
    "save_fig_as_div(fig, file_name=\"charts/average-article-length-bar-chart.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-10T23:11:16.779152100Z",
     "start_time": "2024-02-10T23:11:15.654980800Z"
    }
   },
   "outputs": [],
   "source": [
    "categories_text_df = dfTrain.groupby(by=\"topic\").agg({\"question_content\": \" \".join}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-10T23:11:17.720172600Z",
     "start_time": "2024-02-10T23:11:17.676864600Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_word_cloud(category_name, category_text):\n",
    "    plt.subplots(figsize=(8, 8))\n",
    "    wc = WordCloud(\n",
    "        background_color=\"white\", stopwords=en_stop_words, width=1000, height=600\n",
    "    )\n",
    "    wc.generate(category_text)\n",
    "    plt.title(label=category_name)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "La seguente word-cloud ci aiuterà a dare uno sguardo ai dati e al suo contenuto.\n",
    "\n",
    "Per ogni word cloud, le parole con una frequenza maggiore hanno una dimensione maggiore.\n",
    "\n",
    "Questo ci aiuterà a capire quali sono le parole più frequenti in ogni topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for idx, row in categories_text_df.iterrows():\n",
    "    plot_word_cloud(row[\"topic\"], row[\"question_content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notiamo che le parole più comunemente usate, che però non rispecchiano il topic sono: \n",
    "- think\n",
    "- would\n",
    "- get\n",
    "- want\n",
    "\n",
    "Quindi sono state aggiunte alla lista di stopwords."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "In questo passaggio, costruiremo un **text vectorization** transformer che verrà utilizzato per convertire le domande grezze in funzionalità appropriate, preparate per essere inserite negli algoritmi di machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "Definiamo un *custom vectorizer* chiamato `NLTKVectorizer`. Questo vectorizer eredita il `TfidfVectorizer` e sovrascrive il metodo `build_analyzer`. Il vectorizer risultante avrà gli stessi parametri del `TfidfVectorizer` ma analizzerà i documenti in modo diverso, principalmente utilizzerà il tokenzier `NLTK`, lemmatizer."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorizer e tipi di modelli"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Qui di seguito viene definito il vectorizer e i modelli che verranno presi in considerazione"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-19T15:58:46.265941700Z",
     "start_time": "2024-02-19T15:58:37.915629Z"
    }
   },
   "outputs": [],
   "source": [
    "# text vectorizer\n",
    "vectorizer = NLTKVectorizer(\n",
    "    stop_words=en_stop_words, max_df=0.5, min_df=10, max_features=10000\n",
    ")\n",
    "\n",
    "# Logistic Regression classifier\n",
    "lr_clf = LogisticRegression(C=1.0, solver=\"newton-cg\", multi_class=\"multinomial\", n_jobs=1, verbose=2)\n",
    "\n",
    "# Naive Bayes classifier\n",
    "nb_clf = MultinomialNB(alpha=0.01)\n",
    "\n",
    "# SVM classifier\n",
    "svm_clf = LinearSVC(C=1.0, verbose=2)\n",
    "\n",
    "# Random Forest classifier\n",
    "random_forest_clf = RandomForestClassifier(\n",
    "    n_estimators=100, criterion=\"gini\", max_depth=50, random_state=0, n_jobs=1, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-19T15:59:32.099586800Z",
     "start_time": "2024-02-19T15:59:32.002250400Z"
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline object\n",
    "pipeline = Pipeline([(\"vect\", vectorizer), (\"clf\", lr_clf)])\n",
    "#pipeline = Pipeline([(\"vect\", vectorizer), (\"clf\", svm_clf)])\n",
    "#pipeline = Pipeline([(\"vect\", vectorizer), (\"clf\", random_forest_clf)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creazione della pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "Creo la pipeline con il modello migliore e il vectorizer a cui passo le stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = pipeline.predict(X_test)\n",
    "#y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "## Classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "target_names = [0, 1, 2, 3 ,4 ,5 ,6, 7, 8 ,9]\n",
    "target_names=list(map(str,target_names))\n",
    "classes = target_names\n",
    "fig = get_classification_report(\n",
    "    y_true=y_test, y_pred=y_pred, target_names=classes\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-19T15:25:03.696809800Z",
     "start_time": "2024-02-19T15:25:03.443249500Z"
    }
   },
   "outputs": [],
   "source": [
    "save_fig_as_div(fig_obj=fig, file_name=\"charts/classification-report_svc.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "## Confusion matrix con calcolo diagonale e totale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = get_confusion_matrix(y_true=y_test, y_pred=y_pred, labels=pipeline.classes_)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "heading_collapsed": "false",
    "ExecuteTime": {
     "end_time": "2024-02-18T23:17:47.191996800Z",
     "start_time": "2024-02-18T23:17:46.795335300Z"
    }
   },
   "outputs": [],
   "source": [
    "save_fig_as_div(fig_obj=fig, file_name=\"charts/confusion-matrix_lr.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grid Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tramite la grid search possiamo trovare i migliori parametri per il migliore modello da utilizzare"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # vectorizer hyper-parameters\n",
    "    #'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vect__ngram_range': [(1, 1)],\n",
    "    #'vect__max_df': [0.4, 0.5, 0.6],\n",
    "    'vect__max_df': [0.5],\n",
    "    #'vect__min_df': [10, 50, 100],\n",
    "    'vect__min_df': [10],\n",
    "    #'vect__max_features': [5000, 10000],\n",
    "    'vect__max_features': [10000],\n",
    "    # classifiers\n",
    "    'clf': [lr_clf, nb_clf, svm_clf, random_forest_clf]\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=12)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-19T16:00:05.809857300Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Dump"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T21:34:32.617476700Z",
     "start_time": "2024-02-19T21:34:32.553953Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dump(pipeline, 'dump/model_lr.joblib')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pipeline = load('dump/model_lr.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T21:34:34.640908700Z",
     "start_time": "2024-02-19T21:34:32.617476700Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carichiamo il modello e utilizziamolo per fare delle previsioni"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = input('Enter your question: ')\n",
    "\n",
    "predictProba = pipeline.predict_proba([text])\n",
    "\n",
    "array = [\"Society & culture\", \"Science & Mathematics\", \"Health\", \"Education & Reference\", \"Computers & Internet\", \"Sports\", \"Business & Finance\", \"Entertainment & Music\", \"Family & Relationships\", \"Politics & Government\"]\n",
    "stat = predictProba[0][pipeline.predict([text])[0]] * 100\n",
    "\n",
    "print(\"\\\"\" + text + \"\\\"\" + \"\\n\" \" is about: \" + \"\\\"\" + array[pipeline.predict([text])[0]]+ \"\\\"\" +\"\\n\"+\" with a probability of \" +\"%.3f\" %stat + \"%\" \"\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"\\t\\t\\t\"+ array[i] + \" : \" + \"%.3f\" % (predictProba[0][i] * 100) + \"%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
